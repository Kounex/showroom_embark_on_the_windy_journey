= Prerequisites

In order to start the whole exercise from the {ocpai} perspective, we will need to deploy and configure some applications and resources which will be used later on:

== {ocpai} Project

The most important aspect of this workshop is going to be working at the {ocpai} part. There you will be able to setup everything needed for model training and serving. While we will still have other prerequisites before we can actually jump into the AI part, we want to already create a project there because it will also create a dedicated `namespace`. We will then use this created `namespace` for all resources later on so everything you do is bundled there!

=== Create a {ocpai} Project

To access {ocpai}, simply click on the hamburger menu at the upper right hand corner which opens up a popup where you can simply click on {ocpai}:

image::ocpai-access.png[Access OpenShift AI]

This will open up another tab where you need to press the *Log in with OpenShift* button and login again using your credentials (`{user}` with `{password}`). After that, you should see the actual {ocpai} dashboard. Navigate to *Data Science Projects* from the nav bar on the left and create a new project from there:

image::ocpai-project.png[OpenShift AI Project Creation]

Make sure to name your project `{user}` so you will be able to distinguish it from the others. That's already it! To double check that it worked correctly and we also have a `namespace` to work with, head back to the {ocpc}, navigate to *Projects* (under *Home* in the Administrator view) and search for the `{user}` project. If you were not able to find it there, make sure you actually created a data science project in {ocpai}.

NOTE: Creating a data science project is actually "only" creating a `namespace` in the background. The reason you don`t see all `namespaces` as data science projects is because for a `namespace` to also be a data science project it needs a specific label: `opendatahub.io/dashboard: "true"`. You could add this label to an existing `namespace` and you would have another data science project!

== MinIO

The model we want to train and use later on needs to reside somewhere. {ocpai} has a feature which is called *Data Connection* where we can reference storage used for serving our model later on. This storage needs to be an S3 bucket, therefore we will make use of MinIO which enables us to create such buckets in our cluster.

=== Install MinIO:

. We need to import the relevant YAML resources for the MinIO deployment. Head to the Import YAML view (reminder: plus icon at the upper right hand corner). Make sure you have your project selected currently, you can see it in the import YAML view:
+
image::minio-import-yaml.png[Create a new project in OpenShift]
+
NOTE: The project name should be `{user}` instead of `userxy` as seen in the image above

. In the Import YAML view, paste the following resources and click on `create`:
+
[source,yaml,role=execute]
----
apiVersion: v1
kind: Service
metadata:
  labels:
    app: minio
    app.kubernetes.io/component: minio
    app.kubernetes.io/instance: minio
    app.kubernetes.io/name: minio
    app.kubernetes.io/part-of: minio
    component: minio
  name: minio
spec:
  ports:
    - name: api
      port: 9000
      targetPort: api
    - name: console
      port: 9090
      targetPort: 9090
  selector:
    app: minio
    app.kubernetes.io/component: minio
    app.kubernetes.io/instance: minio
    app.kubernetes.io/name: minio
    app.kubernetes.io/part-of: minio
    component: minio
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  labels:
    app: minio
    app.kubernetes.io/component: minio
    app.kubernetes.io/instance: minio
    app.kubernetes.io/name: minio
    app.kubernetes.io/part-of: minio
    component: minio
  name: minio
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    app: minio
    app.kubernetes.io/component: minio
    app.kubernetes.io/instance: minio
    app.kubernetes.io/name: minio
    app.kubernetes.io/part-of: minio
    component: minio
  name: minio-root-user
type: Opaque
stringData:
    MINIO_ROOT_USER: minio
    MINIO_ROOT_PASSWORD: minio123
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: minio
    app.kubernetes.io/component: minio
    app.kubernetes.io/instance: minio
    app.kubernetes.io/name: minio
    app.kubernetes.io/part-of: minio
    component: minio
  name: minio
spec:
  replicas: 1
  selector:
    matchLabels:
      app: minio
      app.kubernetes.io/component: minio
      app.kubernetes.io/instance: minio
      app.kubernetes.io/name: minio
      app.kubernetes.io/part-of: minio
      component: minio
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: minio
        app.kubernetes.io/component: minio
        app.kubernetes.io/instance: minio
        app.kubernetes.io/name: minio
        app.kubernetes.io/part-of: minio
        component: minio
    spec:
      containers:
        - args:
            - minio server /data --console-address :9090
          command:
            - /bin/bash
            - -c
          envFrom:
            - secretRef:
                name: minio-root-user
          image: quay.io/minio/minio:latest
          name: minio
          ports:
            - containerPort: 9000
              name: api
              protocol: TCP
            - containerPort: 9090
              name: console
              protocol: TCP
          resources:
            limits:
              cpu: "1"
              memory: 1Gi
            requests:
              cpu: 250m
              memory: 512Mi
          volumeMounts:
            - mountPath: /data
              name: minio
      volumes:
        - name: minio
          persistentVolumeClaim:
            claimName: minio
        - emptyDir: {}
          name: empty
---
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  labels:
    app: minio
    app.kubernetes.io/component: minio
    app.kubernetes.io/instance: minio
    app.kubernetes.io/name: minio
    app.kubernetes.io/part-of: minio
    component: minio
  name: minio-console
spec:
  port:
    targetPort: console
  tls:
    insecureEdgeTerminationPolicy: Redirect
    termination: edge
  to:
    kind: Service
    name: minio
    weight: 100
  wildcardPolicy: None
---
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  labels:
    app: minio
    app.kubernetes.io/component: minio
    app.kubernetes.io/instance: minio
    app.kubernetes.io/name: minio
    app.kubernetes.io/part-of: minio
    component: minio
  name: minio-s3
spec:
  port:
    targetPort: api
  tls:
    insecureEdgeTerminationPolicy: Redirect
    termination: edge
  to:
    kind: Service
    name: minio
    weight: 100
  wildcardPolicy: None
----
+
NOTE: You can see that none of the YAML resources above mention a `namespace` attribute. This is because this makes it more flexible so that the used `namespace` will be derived from the currently selected one. That's why it's important to create one before and make sure it's selected.
+
.. Feel free to check the resources which are being generated. A small rundown on these:
+
... `Deployment`: the main resource which will reference the used MinIO image and deploy it
... `Service`: define how the deployment will be accessible from a network perspective - mainly port definitions
... `PersistentVolumeClaim`: MinIO will enable us to create and expose S3 buckets, therefore object storage - that needs storage to begin with and this resource will attach storage to MinIO which it can then use
... `Secret`: contains the credentials for the root user of your MinIO instance
... `Route`: two of them, references the used `Service` to expose it and make it available outside the your cluster - in this case for the API and the Console (UI) of MinIO

NOTE: The login credentials for your MinIO instance can be seen in the `Secret`, it's `minio` with `minio123`.

=== Create a bucket

In order to make use of the Object Storage capabilities of MinIO, we need to create a bucket. We will later upload our model into this bucket and be able to do the inferencing from there. Our MinIO deployment comes with two `Routes`, one for the API to consume the bucket and one for the Console (Web UI). Let's head over to the Console to create our bucket now!

First we need to find out the URL to access the Console. To do so, head over to the *Network* tab in the Administrator view and then to *Routes*. Now make sure your current project is {user}. This should show you the `Routes` which exist in this project, at this state the ones from MinIO. You can already see the *Location* property on the right site, just click on that!

image::minio-route.png[MinIO Route and URL for the Web Console]

There you need to login with the credentials used in the `Secret` when you applied all the YAML manifests for deploying MinIO in the first place. They were `minio` with `minio123`. After logging in, you will already be greeted with the bucket view which is recommending you to create your first bucket, so let's just do that:

image::minio-create-bucket.png[Create a bucket in MinIO]

Use `{global-name}` for the bucket name as this will be the name for almost all resources going forward to minimize potential mix-ups.

The only thing left for us to configure for MinIO, is to set a region. Later on when creating a so called *Data Connection* in {ocpai}, we need to add a region, therefore we will set it in MinIO. To do so, we only need to head over to *Configuration* where we can set this under *Region*, *Server Location*:

image::minio-region-config.png[MinIO region setting]

Just put in `us-east` there.

With that we have everything set up to get started with the {ocpai} topic!