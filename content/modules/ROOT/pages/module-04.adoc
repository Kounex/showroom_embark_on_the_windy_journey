= Model Serving

== Prerequisites
- Your workbench is configured and running.
- You have a data connection
- The git repo is cloned 
For all steps see Module `{ocpai} workbench`


== Download a pre-trained model and upload it to your S3 bucket

In case you have to not had the time or resources to train the model by yourself, you can now download a pre-trained model and upload it to your S3 bucket.

* Open your workbench
* Navigate to `windy-journey/ml/pytorch` and open `02_Visual_Inspection_Upload_Pretrained_Model.ipynb`
* Run the notebook to upload the model

== Configure {ocpai} model serving

Switch to the {ocpai} web console, navigate to *Data Science Project* and select your project `{user}`.

* Create model server in your data science project
 ** Models and model servers \-> *`Add model server`*
 ** Server name: `{global-name}`
 ** Serving runtime: `OpenVINO Model Server`
 ** Number of model server replicas to deploy: `1`
 ** Model server size: `Small`
 ** Model route: \-> `Check/Enable` _'Make deployed models available through an external route'_
 ** Token authorization \-> `Uncheck/Disable` _'Require token authentication'_
 ** \-> *`Add`*
* Deploy the trained model \-> *`Deploy Model`*
 ** Model Name: `{global-name}`
 ** Model framework: `onnx - 1`
 ** Model location: `Existing data connection`
 ** Name: `{global-name}`
 ** Folder path: `{global-name}.onnx`
 ** \-> *`Deploy`*
* Wait until Status is green / loaded
 ** Copy and save the inference URL

NOTE: Please check that the inference endpoint URL does not contain any `undefined` string. The URL should look similar like `\https://{global-name}-user2.apps.cluster-kn7m7.sandbox1697.opentlc.com/v2/models/{global-name}/infer`. In case your URL contains `undefined` string, please delete the model and re-deploy it with another name. E.g. `abc` instead of `{global-name}`.

== Test inferencing with a REST API call

Try out how an ML REST call could be integrated into your 'intelligent' Python application.

* Return to the workbench
* Navigate to `windy-journey/ml/pytorch` and open `03_Visual_Inspection_YOLOv5_Infer_Rest.ipynb`
* Explore and run cells step by step
 ** Please don't forget to update the inferencing URL